{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Selenium抓取台股大盤指數歷史資料.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVmjv6QKOTsaTD0pmGCmIE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcjoey/PythonStock/blob/master/Selenium%E6%8A%93%E5%8F%96%E5%8F%B0%E8%82%A1%E5%A4%A7%E7%9B%A4%E6%8C%87%E6%95%B8%E6%AD%B7%E5%8F%B2%E8%B3%87%E6%96%99.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zXuJmY19k2s"
      },
      "source": [
        "抓取台股大盤指數歷史資料\n",
        "大盤指數本身雖然不像 ETF 般可以直接購買，但大盤指數可以反映目前台灣股市的整體景氣變化，故仍有一定參考性。台股證交所內建的 CSV 下載連結只能取得單月份的數據，對於中長期的分析來說不太方便。本文實作一個可以爬取中長期大盤指數的爬蟲，透過本爬蟲，可以自動化取得連續數年的大盤指數，對於後續的分析比較方便。\n",
        "同樣地，我們先拆解抓取大盤指數所進行的動作：\n",
        "\t• 前往大盤指數歷史數據網站\n",
        "\t• 選取特定年份\n",
        "\t• 選取特定月份\n",
        "\t• 按下查詢按鈕\n",
        "\t• (需用爬蟲) 抓取該月份的歷史數據\n",
        "\t• (需用爬蟲) 重新選取另一個年份、月份後再查詢\n",
        "由此可知，如果這個動作用純手動，要抓取跨月資料時會有困難；這時候，就很適合用爬蟲來減少不必要的手工。\n",
        "由於這個程式碼略長，我們將完整的程式碼放在這裡，除了可以追蹤程式碼，這段程式碼也是一個立即可用的命令列工具，只要台股證交所網站不改版就可以繼續使用。接下來，我們會拆解這段程式碼，供有興趣學習實作的讀者參考。\n",
        "引入相關的套件：\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "From <https://michaelchen.tech/selenium/taiex-historical-data-crawler/> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y51_1y_T91uy"
      },
      "source": [
        "import csv\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "from selenium import webdriver\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TPYFIvi_vdJ"
      },
      "source": [
        "P.S.如果在Colab內還未安裝Webdriver,請依照以下步驟安裝\n",
        "如果已經裝過,就跳過\n",
        "How can we use Selenium Webdriver in colab.research.google.com?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEQRViKVFxwZ"
      },
      "source": [
        "# install chromium, its driver, and selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "# set options to be headless, ..\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "# open it, go to a website, and get results\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "driver.get(\"https://www.website.com\")\n",
        "print(driver.page_source)  # results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJz0qWi9-Li0"
      },
      "source": [
        "設置時距："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGgADdMJ-Izd"
      },
      "source": [
        "validDurations = ['YTD', '1Y', '3Y', '5Y', '10Y', 'Max']\n",
        "duration = 'YTD'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azUkJYGk-aBh"
      },
      "source": [
        "原本證交所上的網頁並沒有中長期時距的概念，這段時距是我們自行加上去的。讀者若有需要也可自行加入其他的時距。\n",
        "設置相關時間點："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLtjhLzu-WWU"
      },
      "source": [
        "now = datetime.datetime.now()\n",
        "year = None\n",
        "month = now.month\n",
        "if duration == 'YTD':\n",
        "    year = now.year\n",
        "    month = 1\n",
        "elif duration == '1Y':\n",
        "    year = now.year - 1\n",
        "elif duration == '3Y':\n",
        "    year = now.year - 3\n",
        "elif duration == '5Y':\n",
        "    year = now.year - 5\n",
        "elif duration == '10Y':\n",
        "    year = now.year - 10\n",
        "elif duration == 'Max':\n",
        "    year = 88 + 1911\n",
        "    month = 1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_17kFdqk9kPW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa1CZyxW-vmf"
      },
      "source": [
        "我們會有兩個日期點，一個是目前的日期 now 物件，一個是目標日期 year 和 month，我們的迴圈需要這兩個日期點判斷迴圈結束的時機。\n",
        "建立使用 Chrome 的 web driver："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGFVJYZ5AE6d"
      },
      "source": [
        "# Create a new instance of the Chrome driver\n",
        "driver = webdriver.Chrome()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1zsJUPAN4a"
      },
      "source": [
        "前往大盤指數所在的頁面："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJjZoTrPAVeC"
      },
      "source": [
        "# Go to TAIEX page\n",
        "driver.get(\"http://www.twse.com.tw/zh/page/trading/indices/MI_5MINS_HIST.html\")\n",
        "# Wait the page to fresh.\n",
        "time.sleep(10)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4drCTbQAc1t"
      },
      "source": [
        "頁面需要暫停數秒，待網頁載入完成。\n",
        "抓取查詢按鈕："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4h0V2AwAaYL"
      },
      "source": [
        "queryBtn = driver.find_element_by_css_selector(\".main a\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2uNPgvdAqRo"
      },
      "source": [
        "現在不用急著按下查詢鈕，待會會在適當的時間按下查詢鈕。\n",
        "準備進入這隻爬蟲最重要的部分，按月份爬取大盤指數歷史數據："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "yfHt2U_dArb-",
        "outputId": "d30508dc-9ddd-4de2-92be-c5d8bc880fa7"
      },
      "source": [
        "data = []\n",
        "isEnd=False\n",
        "currYear = year\n",
        "currMonth = month\n",
        "# Select the initial year.\n",
        "ys = driver.find_elements_by_css_selector(\"select[name=\\\"yy\\\"] option\")\n",
        "for y in ys:\n",
        "    if y.get_attribute(\"value\") == str(currYear):\n",
        "        y.click()\n",
        "        time.sleep(2)\n",
        "        break\n",
        "while not isEnd: \n",
        "  # Run the crawler here."
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-81eda1d08ec9>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    # Run the crawler here.\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8wQP7PjAwfv"
      },
      "source": [
        "我們在這裡從時距的過去日期 (past date) 開始爬，所以 currYear 和 currMonth 會以過去日期來設置。為什麼要從過去日期開始爬？因為我們想要歷史資料的日期是順向的，這樣就不用爬取後再把數據反向。順向的數據對於數據的視覺化來說會比較方便，因為習慣上圖表的左方代表先前日期的交易數據。\n",
        "我們在這裡會先預選一次年份，這樣之後再跑迴圈時不同每個月重新選取年份。這是筆者邊寫程式邊觀察爬蟲的動作所得的結論，不一定適用在所有網站，也不要死記這個手法。\n",
        "由於這個迴圈比較大，我們先把實作的部分移除，只看邏輯的部分："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "saDRO-ZfA07r",
        "outputId": "6faa4850-ec08-433e-d5ec-8dbc714b990e"
      },
      "source": [
        "while not isEnd:   \n",
        "    if currYear < now.year:\n",
        "        if currMonth <= 12:\n",
        "            # Crawl the website.\n",
        "            \n",
        "            currMonth += 1\n",
        "        else:\n",
        "            currMonth = 1\n",
        "            currYear += 1\n",
        "# Crawl the website.\n",
        "    else:\n",
        "        if currMonth <= now.month:\n",
        "            # Crawl the website.\n",
        "            \n",
        "            currMonth += 1\n",
        "        else:\n",
        "            isEnd = True\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-02e512b68cc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misEnd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurrYear\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrMonth\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;31m# Crawl the website.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'isEnd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnBWczpWA6pz"
      },
      "source": [
        "從這段程式碼中看得出來，我們的迴圈就是按月遞增，當迴圈遞增到目前日期時，迴圈就中止。\n",
        "我們來看當目前的年份小於現在年份時的情形："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_avVPt7sBKtp"
      },
      "source": [
        "while not isEnd:   \n",
        "    if currYear < now.year:\n",
        "        if currMonth <= 12:\n",
        "            ms = driver.find_elements_by_css_selector(\"select[name=\\\"mm\\\"] option\")\n",
        "for m in ms:\n",
        "                if m.get_attribute(\"value\") == str(currMonth):\n",
        "                    m.click()\n",
        "                    time.sleep(2)\n",
        "                    queryBtn.click()\n",
        "                    time.sleep(3)\n",
        "items = driver.find_elements_by_css_selector(\"#report-table_wrapper tbody tr\")\n",
        "for item in items:\n",
        "                        tds = item.find_elements_by_css_selector(\"td\")\n",
        "data.append([td.text for td in tds])\n",
        "                    break\n",
        "            \n",
        "            currMonth += 1\n",
        "        else:\n",
        "            currMonth = 1\n",
        "            currYear += 1\n",
        "# Update the year when one year progresses.\n",
        "            ys = driver.find_elements_by_css_selector(\"select[name=\\\"yy\\\"] option\")\n",
        "            \n",
        "            for y in ys:\n",
        "                if y.get_attribute(\"value\") == str(currYear):\n",
        "                    y.click()\n",
        "                    time.sleep(2)\n",
        "                    break\n",
        "    else:\n",
        "        if currMonth <= now.month:\n",
        "            # Crawl the website.\n",
        "            \n",
        "            currMonth += 1\n",
        "        else:\n",
        "            isEnd = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3_aYR9uBQFG"
      },
      "source": [
        "在每個月份中，我們選取特定月份並按下查詢鈕。之後用爬蟲抓取資料，將資料加入 data 串列的尾端。在這裡我們不直接將資料寫入 CSV 檔案，因為爬取時間較久，這樣整個開啟檔案的時間會拉得很長，我們先將數據存在記憶體，整個爬完後再將數據寫入 CSV 檔。\n",
        "當跨到下一個年度時，我們重新選取下一個年份。在這個網頁不需在每個月都選一次年份，可節省一點點操作時間。\n",
        "接下來看一下當下年份等於目前年份的情形："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4k3RVGiBVHu"
      },
      "source": [
        "while not isEnd:   \n",
        "    if currYear < now.year:\n",
        "        if currMonth <= 12:\n",
        "            # Crawl the website.\n",
        "            \n",
        "            currMonth += 1\n",
        "        else:\n",
        "            currMonth = 1\n",
        "            currYear += 1\n",
        "# Crawl the website.\n",
        "    else:\n",
        "        if currMonth <= now.month:\n",
        "            ms = driver.find_elements_by_css_selector(\"select[name=\\\"mm\\\"] option\")\n",
        "for m in ms:\n",
        "                if m.get_attribute(\"value\") == str(currMonth):\n",
        "                    m.click()\n",
        "                    time.sleep(2)\n",
        "                    queryBtn.click()\n",
        "                    time.sleep(3)\n",
        "items = driver.find_elements_by_css_selector(\"#report-table_wrapper tbody tr\")\n",
        "for item in items:\n",
        "                        tds = item.find_elements_by_css_selector(\"td\")\n",
        "data.append([td.text for td in tds])\n",
        "                    break\n",
        "            \n",
        "            currMonth += 1\n",
        "        else:\n",
        "            isEnd = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U14a5g1hBbBn"
      },
      "source": [
        "其實爬資料的動作是一樣的，重點是邏輯的部分有變化，我們不會爬完整年份的資料，只會爬到當下月份的資料，因為目前的月份還沒走完，無法取得整年的數據。另外，我們也要在適當的時機結束這個迴圈。\n",
        "我們設置一些字串，這些字串會用到自動化生成檔名："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj3Y0PgmBcAd"
      },
      "source": [
        "def monToStr(m):\n",
        "    if m < 10:\n",
        "        return '0' + str(m)\n",
        "    else:\n",
        "        return str(m)\n",
        "pastDateStr = \"%d%s\" % (year, monToStr(month))\n",
        "currDateStr = \"%d%s\" % (now.year, monToStr(now.month))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5pZV2DCBgAX"
      },
      "source": [
        "將歷史數據寫入 CSV 檔："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx5VO8UzBmNW"
      },
      "source": [
        "with open(\"TAIEX_%sto%s.csv\" % (pastDateStr, currDateStr), 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "csvwriter.writerow([\"Date\", \"Open\", \"High\", \"Low\", \"Close\"])\n",
        "for d in data:\n",
        "        csvwriter.writerow(d)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAr4VH5FBqAn"
      },
      "source": [
        "最後別忘了關掉瀏覽器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4lHXq_VBwP3"
      },
      "source": [
        "# Close the browser.\n",
        "driver.quit()\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqmjhkYKB0lR"
      },
      "source": [
        "透過這個程式，我們就可以取得中長期的大盤指數歷史數據。由於原本證交所網站沒有中長期時距的概念，我們在程式中自行加入；另外，我們也可以練習如何用 Selenium 取得跨月份的歷史數據。這些都是實作這隻爬蟲時學到的寶貴經驗。"
      ]
    }
  ]
}